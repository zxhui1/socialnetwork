我们来写一下social network的小结：

1. 我们获得了一些数据：
@以任何一个人为中心逐层展开的follower网络，从这个网络中我们可以知道一个人的follower，follower的follower等等。
@任意一个程序的star数量从程序创建开始的时间变化，大致有三类：直线增长的，增长至一个饱和期并且在一段时间后又开始增长的，增长至一个饱和期后基本不再变化的。
@有一个时间点很重要，就是2013年2月初，在引入了全代码搜索以及按照程序star数量和user的follower数量排名的搜索引擎以后，star数量的增长情况发生了很大的变化，很多程序的star数量原本进入饱和，却在引入这种搜索引擎以后开始了直线增长。
@我们还有一些关于这个follower网络的一些基本静态数据，比如许多描述网络结构的参数我们都可以测量。

2. 我们有一个简单的模型来解释star数量的变化规律

基础：和传染病的传播类似，有两种基本情况：1. 传播能力强，越来越多的人来star这个程序，呈现不断上升态势，这个数学上虽然不是严格直线，但是在一段时间内与直线很接近。2. 传播能力弱，在一定数量的人star这个程序以后，没有继续传播下去，人数达到饱和。这个我已经给你看过换出来的曲线形状，与真实数据很相似。

变化：
@饱和之后还会继续增长，跟程序又有新的改进（commit）有直接相关。这说明改进程序（当然要足够多的改进，commit数量有一个峰值，我猜这峰值可能代表程序升级）会迎来新的一轮传播。

@有搜索引擎按star数量排名以后，很多原本已经有一定star积累的程序会不断地被人们搜索出来，直接结果就是如果某个程序的star数量足够，它的star数量就不会饱和，而是在最初的增长后继续直线增长。直线的斜率代表了单位时间内通过搜索来star程序的人数，这个斜率具有一定的意义。之所以增长率是直线，我们可以认为这是一种规律，代表了每时每刻从搜索来发现这个程序的人数实际上事比较稳定的。（这其实说明preferential attachment的大意是对的，star高可以吸引到更多的人关注，但这里因为搜索引擎给的结果是依据排名来的，所以并不是与star数成正比，而是与star的排名有关）

模型计算：
非常简单，假设一个人的第一层follower有N1个，star这个程序的概率是P1,每一个follower平均又有N2个follower，star的概率是P2，。。。
那么总star数就是 N1*P1+N1*P1*N2*P2+N1*P1*N2*P2*N3*P3+....
假设N2=N3=N4=...=c,P2=P3=P4=...=p, 
star总数 = N1*P1+N1*P1*c*p*(1-(c*p)^n)/(1-c*p)
这是当传播到第n层的时候star的总数
我们可以假设每一层传播的时间是一样的，那么n就正比于时间。
如果c*p>1,那么这个函数就不断增加
如果c*p<1,那么这个函数就会一开始快速增加，随后就饱和，饱和值是
N1*P1+N1*P1*c*p/(1-c*p)
如果这个饱和值超过某个临界NC，我们就加入一个线性项k*n，这代表搜索

模拟：

对于任何一个人我们可以在他的follower网络模拟这个传播过程，也可以得到与上述结果类似的结果

文章：
Introduction
第一段：虚拟社区
第二段：复杂网络
第三段：github的特殊性
第四段：文章结构
Background










